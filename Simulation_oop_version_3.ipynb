{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for Simulator - updates Geojson file with Completion status and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import random\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.enums import Resampling\n",
    "from tatc.schemas import TwoLineElements\n",
    "from tatc.schemas import Point\n",
    "from tatc.analysis import collect_observations\n",
    "from tatc import utils\n",
    "from tatc.schemas import Instrument\n",
    "from tatc.schemas import WalkerConstellation, SunSynchronousOrbit\n",
    "from tatc.utils import (\n",
    "    swath_width_to_field_of_regard,\n",
    "    along_track_distance_to_access_time,\n",
    ")\n",
    "import datetime\n",
    "from tatc.analysis import collect_multi_observations\n",
    "from tatc.schemas import Satellite\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from tatc.schemas import Point\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from tatc.analysis import collect_ground_track\n",
    "from tatc.analysis import compute_ground_track\n",
    "from tatc.schemas import PointedInstrument, WalkerConstellation, SunSynchronousOrbit\n",
    "from tatc.utils import swath_width_to_field_of_regard, swath_width_to_field_of_view\n",
    "import pytz\n",
    "\n",
    "class Simulator():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # This function uses the tatc library to define the  Snow_globe Constellation, we define tle, instrument \n",
    "    \n",
    "    def const(self):\n",
    "        roll_angle = (30 + 33.5)/2\n",
    "        roll_range = (33.5 - 30)\n",
    "        start = datetime(2018, 1, 1, tzinfo=timezone.utc)\n",
    "        self.constellation = WalkerConstellation(\n",
    "            name=\"SnowGlobe Ku\",\n",
    "            orbit=SunSynchronousOrbit(\n",
    "                altitude=555e3, \n",
    "                equator_crossing_time=\"06:00:30\", \n",
    "                equator_crossing_ascending=False,\n",
    "                epoch=start\n",
    "            ),\n",
    "            number_planes=1,\n",
    "            number_satellites=5,\n",
    "            instruments=[\n",
    "                PointedInstrument(\n",
    "                    name=\"SnowGlobe Ku-SAR\",\n",
    "                    roll_angle=-roll_angle,\n",
    "                    field_of_regard=2*roll_angle + swath_width_to_field_of_regard(555e3, 50e3),\n",
    "                    along_track_field_of_view=swath_width_to_field_of_view(555e3, 50e3, 0),\n",
    "                    cross_track_field_of_view=roll_range + swath_width_to_field_of_view(555e3, 50e3, roll_angle),\n",
    "                    is_rectangular=True\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        satellites = self.constellation.generate_members()\n",
    "        self.satellite_dict = {sat.name: sat for sat in satellites}\n",
    "\n",
    "    # This function reads the master geojson file and filter unprocessed requests\n",
    "    # (non empty simulation status indicates, that location/request was processed) \n",
    "    # key output = self.filtered_req (pandas dataframe with filtered rows )  \n",
    "    \n",
    "    def user_request(self):\n",
    "        self.req = gpd.read_file('Master_file')      \n",
    "        self.filtered_req = self.req[self.req['simulation_status'].isna() | (self.req['simulation_status'] == \"None\")]         \n",
    "\n",
    "    # This function uses tatc library multi - observations to generate the list of observation times\n",
    "    # It uses all the locations from the user_request function, the simulation time at each step is given as input    \n",
    "    # key output = self.combined_results, is a pandas data frame, column epoch returns the obs time (we sort it ascending)\n",
    "\n",
    "    def opportunity(self):\n",
    "        self.const()\n",
    "        self.user_request()\n",
    "        end = self._time + timedelta(2)\n",
    "        combined_results = pd.DataFrame()\n",
    "        for index,row in self.filtered_req.iterrows():    \n",
    "            loc = Point(id=row['id'],latitude=row['latitude'],longitude=row['longitude'])\n",
    "            results = collect_multi_observations(loc, self.constellation, self._time, end)\n",
    "            combined_results = pd.concat([combined_results, results], ignore_index=True)    \n",
    "        self.combined_results = combined_results.sort_values(by='epoch', ascending=True)\n",
    "        \n",
    "   # whenever the planner uploades geojson file we want requests to be updated\n",
    "   # (to incorporate changes from optimizer or updates from simulation , ie simulation status updates)\n",
    "   \n",
    "    def execute(self,init_time, duration, time_step): \n",
    "        # intilization\n",
    "        self.const()\n",
    "        self.user_request()\n",
    "        self._time = self._next_time = self._init_time = init_time\n",
    "        self._duration = duration\n",
    "        self._time_step = time_step\n",
    "\n",
    "        while self._time < self._init_time + self._duration:\n",
    "            counter = 0\n",
    "            print(f\"Current time {self._time}\")            \n",
    "            self._next_time = self._time + self._time_step\n",
    "            print(f\"advancing to {self._next_time}\") \n",
    "\n",
    "            # updating user requests - read filtered rows\n",
    "            # Logic if appender completes execution then execute below line\n",
    "            \n",
    "            self.user_request() # reading updated master file        \n",
    "\n",
    "            # Error handler\n",
    "            if self.filtered_req.empty:\n",
    "                logging.info(\"No observations available. Skipping to next time step.\")\n",
    "                # Can use this condition to reset the master file\n",
    "                # self._time = self._next_time\n",
    "                continue\n",
    "            \n",
    "            self.opportunity() # updating observations list\n",
    "            if self.combined_results.empty:\n",
    "                logging.error(\"combined_results is empty! No observations until next time step! Skipping to next\")\n",
    "                # self._time = self._next_time\n",
    "                continue\n",
    "            \n",
    "\n",
    "            self.rs = self.combined_results # writing the observations pandas dataframe to new variable\n",
    "            self.observation_time = self.rs['epoch'].iloc[0] # latest possible observation            \n",
    "            self.id = self.rs['point_id'].iloc[0] # point id for the above observation\n",
    "            self.coord = self.rs['geometry'].iloc[0] # location for the observation\n",
    "            self.sat = self.rs['satellite'].iloc[0] # satellite collecting the observation\n",
    "            prev_observation_time = None\n",
    "            # This below loop is written to handle the time step(1 day), there can be multiple observations within a day \n",
    "            # it loops through all the observations possible until the next time step\n",
    "\n",
    "            while self.observation_time < self._next_time:\n",
    "                if self.observation_time == prev_observation_time:\n",
    "                    logging.warning(\"No progress in observations, breaking loop.\")\n",
    "                    break\n",
    "                prev_observation_time = self.observation_time\n",
    "                print(f\"Next observation {self.observation_time}\") \n",
    "                req = self.req # reads the requests file\n",
    "                #req = pd.read_excel('requests.xlsx')\n",
    "                req['completion_date'] = pd.to_datetime(req['completion_date'], errors='coerce')  # Ensure completion_date is datetime\n",
    "                req['simulation_status'] = req['simulation_status'].astype(str)  # Ensure simulation_status is string\n",
    "                # req['request_status'] = req['request_status'].astype(str)\n",
    "                req['satellite'] = req['satellite'].astype(str)\n",
    "                # format time as required in gejson file\n",
    "                t = self.observation_time\n",
    "                # t = self.observation_time.replace(tzinfo=None)\n",
    "                \n",
    "                # Groundtrack information\n",
    "\n",
    "                # The below lines updates the excel file for the specific id corresponding to the latest observation time\n",
    "                # ps note, the locations are not processed sequentially as in excel, id 13 can be processed before id 1 based on satellite location                            \n",
    "\n",
    "                req.loc[req.id == self.id, 'completion_date'] = t\n",
    "                req.loc[req.id == self.id, 'simulation_status'] = 'Completed'\n",
    "                # req.loc[req.id == self.id, 'request_status'] = 'Completed'\n",
    "                req.loc[req.id == self.id, 'satellite'] = self.sat\n",
    "\n",
    "                # Groundtrack information\n",
    "                sat_object = self.satellite_dict.get(self.sat)\n",
    "                results = collect_ground_track(sat_object,[t],crs='spice')\n",
    "                req.loc[req.id == self.id, 'geometry'] = results['geometry'].iloc[0]         \n",
    "                \n",
    "                # Save the updated DataFrame back to the Master Geojson file\n",
    "                counter += 1\n",
    "                req.to_file(\"Master_file\", driver=\"GeoJSON\")\n",
    "                # Regenerating observations with respect to updated list\n",
    "                # calling user_request and opprtunity will now exclude the entries processed above(sompleted status) and generate new list\n",
    "                self.user_request()\n",
    "\n",
    "                # Error handler\n",
    "                if self.filtered_req.empty:\n",
    "                    logging.info(\"No observations available. Skipping to next time step.\")\n",
    "                # Can use this condition to reset the master file\n",
    "                    # self._time = self._next_time\n",
    "                    continue\n",
    "                \n",
    "                self.opportunity() \n",
    "\n",
    "                if self.combined_results.empty:\n",
    "                    logging.error(\"combined_results is empty! No observations until next time step! Skipping to next\")\n",
    "                    # self._time = self._next_time\n",
    "                    continue\n",
    "\n",
    "                self.rs = self.combined_results\n",
    "                self.observation_time = self.rs['epoch'].iloc[0]\n",
    "                self.id = self.rs['point_id'].iloc[0]\n",
    "                self.coord = self.rs['geometry'].iloc[0]\n",
    "                self.sat = self.rs['satellite'].iloc[0]\n",
    "            # simulation advances to next time\n",
    "            # filter data and write geojson\n",
    "            if counter>0:\n",
    "                self.user_request()\n",
    "                # Filter data for each day(self.time)\n",
    "                file_name = f\"Simulator_Output_{pd.to_datetime(self._time).strftime('%Y-%m-%d')}\"\n",
    "                filtered_data = self.req[self.req['completion_date'].dt.date == pd.to_datetime(self._time).date()]               \n",
    "                filtered_data.to_file(file_name, driver=\"GeoJSON\")                \n",
    "\n",
    "            self._time = self._next_time     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current time 2019-03-10 00:00:00+00:00\n",
      "advancing to 2019-03-11 00:00:00+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dramach6\\AppData\\Local\\Temp\\ipykernel_25188\\125898820.py:158: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2019-03-10 00:02:56.166147500+00:00' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  req.loc[req.id == self.id, 'completion_date'] = t\n",
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:02:56.166147500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:10.059897+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:11.159589+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:11.366266500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:16.257771+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:17.210290500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:18.346353500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:21.654321500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:24.415984500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:25.369630500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:27.256564500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:29.287111+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:31.215505500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:31.541836+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:32.433000+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:32.951343500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:33.889379+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:35.429745+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:38.893476+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:39.646278+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:40.194917+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:40.795578+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:45.288070+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:46.025201+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:56.434419+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:03:59.554679500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:00.639244+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:00.794584+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:03.891369+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:07.881329+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:08.268734+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:15.633470+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:23.271750500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:04:30.825119500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:21:52.677686+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:22:22.064229500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:23:36.522767500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 00:23:53.158726500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:12.223142+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:19.320951+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:26.350303500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:30.929457500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:32.362944500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:33.481707+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:38.003911500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:39.425428500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:46.460856+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:17:53.440721500+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyogrio._io:Created 51 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation 2019-03-10 12:18:00.421009500+00:00\n",
      "Next observation 2019-03-10 12:18:07.401137+00:00\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'Master_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m duration \u001b[38;5;241m=\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      6\u001b[0m time_step \u001b[38;5;241m=\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[63], line 170\u001b[0m, in \u001b[0;36mSimulator.execute\u001b[1;34m(self, init_time, duration, time_step)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m# Save the updated DataFrame back to the Master Geojson file\u001b[39;00m\n\u001b[0;32m    169\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 170\u001b[0m \u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMaster_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGeoJSON\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Regenerating observations with respect to updated list\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# calling user_request and opprtunity will now exclude the entries processed above(sompleted status) and generate new list\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_request()\n",
      "File \u001b[1;32mc:\\Users\\dramach6\\AppData\\Local\\anaconda3\\envs\\SOS_4\\lib\\site-packages\\geopandas\\geodataframe.py:1536\u001b[0m, in \u001b[0;36mGeoDataFrame.to_file\u001b[1;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Write the ``GeoDataFrame`` to a file.\u001b[39;00m\n\u001b[0;32m   1442\u001b[0m \n\u001b[0;32m   1443\u001b[0m \u001b[38;5;124;03mBy default, an ESRI shapefile is written, but any OGR data source\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1532\u001b[0m \n\u001b[0;32m   1533\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1534\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgeopandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _to_file\n\u001b[1;32m-> 1536\u001b[0m _to_file(\u001b[38;5;28mself\u001b[39m, filename, driver, schema, index, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dramach6\\AppData\\Local\\anaconda3\\envs\\SOS_4\\lib\\site-packages\\geopandas\\io\\file.py:686\u001b[0m, in \u001b[0;36m_to_file\u001b[1;34m(df, filename, driver, schema, index, mode, crs, engine, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m should be one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 686\u001b[0m     _to_file_pyogrio(df, filename, driver, schema, crs, mode, metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    688\u001b[0m     _to_file_fiona(df, filename, driver, schema, crs, mode, metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dramach6\\AppData\\Local\\anaconda3\\envs\\SOS_4\\lib\\site-packages\\geopandas\\io\\file.py:748\u001b[0m, in \u001b[0;36m_to_file_pyogrio\u001b[1;34m(df, filename, driver, schema, crs, mode, metadata, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m    746\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeoDataFrame cannot contain duplicated column names.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 748\u001b[0m pyogrio\u001b[38;5;241m.\u001b[39mwrite_dataframe(df, filename, driver\u001b[38;5;241m=\u001b[39mdriver, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dramach6\\AppData\\Local\\anaconda3\\envs\\SOS_4\\lib\\site-packages\\pyogrio\\geopandas.py:654\u001b[0m, in \u001b[0;36mwrite_dataframe\u001b[1;34m(df, path, layer, driver, encoding, geometry_type, promote_to_multi, nan_as_null, append, use_arrow, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m geometry_column \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m     geometry \u001b[38;5;241m=\u001b[39m to_wkb(geometry\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m--> 654\u001b[0m write(\n\u001b[0;32m    655\u001b[0m     path,\n\u001b[0;32m    656\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[0;32m    657\u001b[0m     driver\u001b[38;5;241m=\u001b[39mdriver,\n\u001b[0;32m    658\u001b[0m     geometry\u001b[38;5;241m=\u001b[39mgeometry,\n\u001b[0;32m    659\u001b[0m     field_data\u001b[38;5;241m=\u001b[39mfield_data,\n\u001b[0;32m    660\u001b[0m     field_mask\u001b[38;5;241m=\u001b[39mfield_mask,\n\u001b[0;32m    661\u001b[0m     fields\u001b[38;5;241m=\u001b[39mfields,\n\u001b[0;32m    662\u001b[0m     crs\u001b[38;5;241m=\u001b[39mcrs,\n\u001b[0;32m    663\u001b[0m     geometry_type\u001b[38;5;241m=\u001b[39mgeometry_type,\n\u001b[0;32m    664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    665\u001b[0m     promote_to_multi\u001b[38;5;241m=\u001b[39mpromote_to_multi,\n\u001b[0;32m    666\u001b[0m     nan_as_null\u001b[38;5;241m=\u001b[39mnan_as_null,\n\u001b[0;32m    667\u001b[0m     append\u001b[38;5;241m=\u001b[39mappend,\n\u001b[0;32m    668\u001b[0m     dataset_metadata\u001b[38;5;241m=\u001b[39mdataset_metadata,\n\u001b[0;32m    669\u001b[0m     layer_metadata\u001b[38;5;241m=\u001b[39mlayer_metadata,\n\u001b[0;32m    670\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    671\u001b[0m     dataset_options\u001b[38;5;241m=\u001b[39mdataset_options,\n\u001b[0;32m    672\u001b[0m     layer_options\u001b[38;5;241m=\u001b[39mlayer_options,\n\u001b[0;32m    673\u001b[0m     gdal_tz_offsets\u001b[38;5;241m=\u001b[39mgdal_tz_offsets,\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    675\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dramach6\\AppData\\Local\\anaconda3\\envs\\SOS_4\\lib\\site-packages\\pyogrio\\raw.py:709\u001b[0m, in \u001b[0;36mwrite\u001b[1;34m(path, geometry, field_data, fields, field_mask, layer, driver, geometry_type, crs, encoding, promote_to_multi, nan_as_null, append, dataset_metadata, layer_metadata, metadata, dataset_options, layer_options, gdal_tz_offsets, **kwargs)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;66;03m# preprocess kwargs and split in dataset and layer creation options\u001b[39;00m\n\u001b[0;32m    705\u001b[0m dataset_kwargs, layer_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_kwargs(\n\u001b[0;32m    706\u001b[0m     driver, dataset_options, layer_options, kwargs\n\u001b[0;32m    707\u001b[0m )\n\u001b[1;32m--> 709\u001b[0m \u001b[43mogr_write\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeometry_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpromote_to_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpromote_to_multi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnan_as_null\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnan_as_null\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgdal_tz_offsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dramach6\\AppData\\Local\\anaconda3\\envs\\SOS_4\\lib\\site-packages\\pyogrio\\_io.pyx:2298\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_write\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\dramach6\\AppData\\Local\\anaconda3\\envs\\SOS_4\\lib\\site-packages\\pyogrio\\_io.pyx:2089\u001b[0m, in \u001b[0;36mpyogrio._io.create_ogr_dataset_layer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'Master_file'"
     ]
    }
   ],
   "source": [
    "s = Simulator()\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "start = datetime(2019, 3, 10, tzinfo=timezone.utc)\n",
    "duration = timedelta(days=5)\n",
    "time_step = timedelta(days=1)\n",
    "s.execute(start, duration, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>final_eta</th>\n",
       "      <th>Planner_geometry</th>\n",
       "      <th>centroid</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>expiration_date</th>\n",
       "      <th>simulation_status</th>\n",
       "      <th>completion_date</th>\n",
       "      <th>satellite</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-10</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>POLYGON ((-91.94683 37.024602, -91.94683 37.63...</td>\n",
       "      <td>POINT (-92.252265 37.329427)</td>\n",
       "      <td>37.329427</td>\n",
       "      <td>-92.252265</td>\n",
       "      <td>None</td>\n",
       "      <td>Completed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       time  final_eta  \\\n",
       "0   1 2019-03-10   0.003591   \n",
       "\n",
       "                                    Planner_geometry  \\\n",
       "0  POLYGON ((-91.94683 37.024602, -91.94683 37.63...   \n",
       "\n",
       "                       centroid   latitude  longitude expiration_date  \\\n",
       "0  POINT (-92.252265 37.329427)  37.329427 -92.252265            None   \n",
       "\n",
       "  simulation_status completion_date satellite geometry  \n",
       "0         Completed            None      None     None  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master = gpd.read_file('Master_file')\n",
    "filtered_req = master[master['simulation_status'].isna()] \n",
    "filtered_req\n",
    "master.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [geometry]\n",
       "Index: []"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_p = gpd.read_file('Simulator_Output_2019-03-11')\n",
    "o_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOS_4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
